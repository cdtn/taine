{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9087870",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d8439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from batchflow import Pipeline, B, V, I, M, C, plot\n",
    "from batchflow.models.torch import TorchModel, VGGBlock\n",
    "\n",
    "from src.loader import ImagesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2426df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 11\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b25151",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "DATA_PATH = '../images'\n",
    "SHAPE = (128, 128, 3)\n",
    "\n",
    "dataset = ImagesDataset(path=DATA_PATH, encode_labels=True, normalize=True, resize_shape=SHAPE)\n",
    "n_classes = dataset.label_encoder.classes_.size\n",
    "\n",
    "dataset.split(shuffle=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e41d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = rng.choice(range(dataset.size), 8)\n",
    "images = list(dataset.images[indices])\n",
    "labels = list(dataset.labels[indices])\n",
    "plot(data=images, title=labels, combine='separate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'inputs/shapes': SHAPE[::-1],\n",
    "\n",
    "    'body': {\n",
    "        'type': 'encoder',\n",
    "        'output_type': 'tensor',\n",
    "        'order': ['block', 'downsampling'],\n",
    "        'num_stages': 3,\n",
    "        'blocks': {\n",
    "            'base_block': VGGBlock,\n",
    "            'channels': [64, 128, 256],\n",
    "            'depth3': 2,\n",
    "            'depth1': [0, 0, 1],\n",
    "        },\n",
    "    },\n",
    "\n",
    "    'head': {\n",
    "        'layout': 'Vdf',\n",
    "        'dropout_rate': 0.4,\n",
    "        'classes': n_classes\n",
    "    },\n",
    "\n",
    "    'common/conv/bias' : False,\n",
    "\n",
    "    # Model training details:\n",
    "    'init_model_weights': 'xavier',\n",
    "    'loss': 'ce',\n",
    "    'optimizer': 'Adam',\n",
    "    'output': {'predicted': ['proba', 'labels']},\n",
    "    'device': 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a8e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(iteration, frequency, model, metrics, agg):\n",
    "    if (iteration - 1) % frequency == 0:\n",
    "        infer_pipeline = infer_template << dataset.test << {'model': model}\n",
    "        infer_pipeline.run(batch_size=dataset.test.size, n_epochs=1, drop_last=False)\n",
    "        metrics_value = infer_pipeline.v('metrics').evaluate(metrics=metrics, agg=agg)\n",
    "        return [metrics_value] * frequency\n",
    "    return []\n",
    "        \n",
    "train_template = (\n",
    "    Pipeline()\n",
    "    .to_array(channels='first', dtype=np.float32)\n",
    "    .init_variable(name='loss_history', default=[])\n",
    "    .init_variable(name='test_metrics', default=[])\n",
    "    .init_model(name='model', model_class=TorchModel, mode='dynamic', config=model_config)\n",
    "    .train_model(name='model', inputs=B('images'), targets=B('labels'),\n",
    "                 outputs='loss', save_to=V('loss_history', mode='a'))\n",
    "    .call(evaluate, iteration=I(), model=M('model'), frequency=C('evaluate/frequency'),\n",
    "          metrics=C('evaluate/metrics'), agg=C('evaluate/metrics'), save_to=V('test_metrics', mode='e'))\n",
    ")\n",
    "\n",
    "infer_template = (\n",
    "    Pipeline()\n",
    "    .to_array(channels='first', dtype=np.float32)\n",
    "    .init_variables('proba', 'predictions', 'metrics')\n",
    "    .import_model('model', C('model'))\n",
    "    .predict_model(name='model', inputs=B('images'),\n",
    "                   outputs=['predicted_proba', 'predictions'],\n",
    "                   save_to=[V('proba'), V('predictions')])\n",
    "    .gather_metrics('classification', targets=B('labels'), predictions=V('predictions'),\n",
    "                    fmt='logits', num_classes=n_classes,\n",
    "                    axis=1, save_to=V('metrics', mode='update'))\n",
    ")\n",
    "\n",
    "train_config = {\n",
    "    'evaluate': {\n",
    "        'frequency': 50,\n",
    "        'metrics': 'accuracy',\n",
    "    }\n",
    "}\n",
    "\n",
    "train_pipeline = train_template << dataset.train << train_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0808738",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "FREQUENCY = 50\n",
    "EPOCH_NUM = 200\n",
    "\n",
    "notifier = {\n",
    "    'bar': 'n', 'frequency': FREQUENCY,\n",
    "    'graphs': ['loss_history', 'cpu', 'test_metrics'],\n",
    "}\n",
    "\n",
    "_ = train_pipeline.run(batch_size=BATCH_SIZE, n_epochs=EPOCH_NUM, shuffle=True, notifier=notifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd4b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline.model.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8708dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_pipeline = infer_template << dataset.test << {'model': train_pipeline.model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daab223",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_pipeline.run(batch_size=dataset.test.size, n_epochs=1, drop_last=False, bar='t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a0da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_pipeline.v('metrics').plot_confusion_matrix(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092161a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = np.unique(dataset.labels[dataset.test.indices], return_counts=True)\n",
    "shares = counts / counts.sum()\n",
    "\n",
    "metrics = ['precision', 'recall']\n",
    "metrics_dict = infer_pipeline.v('metrics').evaluate(metrics, multiclass=None)\n",
    "metrics_df = pd.DataFrame({'names': dataset.label_encoder.classes_, 'shares': shares, **metrics_dict})\n",
    "\n",
    "formatter = lambda value: value if isinstance(value, str) else f\"{int(value * 100)}%\"\n",
    "metrics_df.style.background_gradient('RdYlGn', vmin=0, vmax=1, subset=metrics).format(formatter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
